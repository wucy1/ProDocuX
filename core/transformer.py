#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æª”è½‰æ›å™¨
å°‡çµæ§‹åŒ–è³‡æ–™è½‰æ›ç‚ºä¸åŒæ ¼å¼çš„æ–‡æª”
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Union, List
from docxtpl import DocxTemplate
import pdfplumber
from docx.oxml.ns import qn

logger = logging.getLogger(__name__)

class DocumentTransformer:
    """æ–‡æª”è½‰æ›å™¨"""
    
    def __init__(self, profile_path: Optional[str] = None):
        """åˆå§‹åŒ–æ–‡æª”è½‰æ›å™¨"""
        # ä»¥ä½¿ç”¨è€…å·¥ä½œç©ºé–“ç‚ºå„ªå…ˆ
        try:
            from utils.settings_manager import SettingsManager
            sm = SettingsManager()
            self.template_dir = Path(sm.get_directory_paths()['template'])
        except Exception:
            # å¾Œå‚™ï¼šå°æ–¼æ‰“åŒ…ç‰ˆæœ¬ï¼Œä½¿ç”¨å·¥ä½œç©ºé–“çš„ templates
            if getattr(sys, 'frozen', False):
                try:
                    from utils.desktop_manager import DesktopManager
                    dm = DesktopManager()
                    self.template_dir = dm.workspace_dir / "templates"
                except:
                    self.template_dir = Path("templates")
            else:
                self.template_dir = Path("templates")
        
        # è¼‰å…¥Profileè³‡è¨Š
        self.profile_fields = {}
        if profile_path:
            self._load_profile(profile_path)
        
        logger.info("Document transformer initialized")
    
    def _load_profile(self, profile_path: str):
        """è¼‰å…¥Profileè³‡è¨Š"""
        try:
            import yaml
            with open(profile_path, 'r', encoding='utf-8') as f:
                profile_data = yaml.safe_load(f)
            
            # æå–æ¬„ä½åç¨±
            if 'fields' in profile_data:
                for field in profile_data['fields']:
                    if isinstance(field, dict) and 'name' in field:
                        self.profile_fields[field['name']] = field
                        logger.debug(f"Loading profile field: {field['name']}")
            
            logger.info(f"Profile loaded: {profile_path}, {len(self.profile_fields)} fields")
        except Exception as e:
            logger.warning(f"Failed to load profile: {e}")
    
    def transform(self, data: Dict[str, Any], 
                 template_path: Union[str, Path],
                 output_path: Union[str, Path],
                 output_format: str = "docx",
                 allow_fallback: bool = False) -> bool:
        """
        è½‰æ›çµæ§‹åŒ–è³‡æ–™ç‚ºæ–‡æª”
        
        Args:
            data: çµæ§‹åŒ–è³‡æ–™
            template_path: æ¨¡æ¿æª”æ¡ˆè·¯å¾‘
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            output_format: è¼¸å‡ºæ ¼å¼ (docx, pdf, json)
            
        Returns:
            è½‰æ›æ˜¯å¦æˆåŠŸ
        """
        try:
            template_path = Path(template_path)
            output_path = Path(output_path)
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            if output_format == "docx":
                return self._transform_to_docx(data, template_path, output_path, allow_fallback)
            elif output_format == "pdf":
                return self._transform_to_pdf(data, template_path, output_path, allow_fallback)
            elif output_format == "json":
                return self._transform_to_json(data, output_path)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„è¼¸å‡ºæ ¼å¼: {output_format}")
                
        except Exception as e:
            logger.error(f"Document transformation failed: {e}")
            # ç›´æ¥æ‹‹å‡ºç•°å¸¸ï¼Œä¸ä½¿ç”¨å›é€€æ©Ÿåˆ¶
            raise Exception(f"æ–‡æª”è½‰æ›å¤±æ•—: {e}")
    
    def _transform_to_docx(self, data: Dict[str, Any], 
                          template_path: Path, output_path: Path, allow_fallback: bool = False) -> bool:
        """è½‰æ›ç‚ºWordæ–‡æª”"""
        try:
            # æª¢æŸ¥æ˜¯å¦ç‚º docx
            if template_path.suffix.lower() != '.docx':
                # å°æ–¼é docxï¼Œå…ˆå˜—è©¦ç›´æ¥è¤‡è£½ï¼ˆç„¡æ¸²æŸ“ï¼‰
                import shutil
                shutil.copy2(template_path, output_path)
                logger.warning("Non-.docx template, copied directly; recommend using .docx for rendering")
                return True

            # æª¢æŸ¥æ¨¡æ¿å…ƒæ•¸æ“šä»¥åˆ¤æ–·æ˜¯å¦å« jinja è®Šæ•¸
            has_jinja = False
            try:
                # é¦–å…ˆæª¢æŸ¥å…ƒæ•¸æ“šæ–‡ä»¶
                meta_path = template_path.parent / f"{template_path.stem}.json"
                if meta_path.exists():
                    import json
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        meta = json.load(f)
                    has_jinja = meta.get('has_jinja', False)
                    placeholders = meta.get('placeholders', [])
                    logger.info(f"Read from metadata: has_jinja={has_jinja}, placeholders={len(placeholders)}")
                else:
                    # å¦‚æœæ²’æœ‰å…ƒæ•¸æ“šæ–‡ä»¶ï¼Œå›é€€åˆ°åŸå§‹æª¢æŸ¥
                    # æ›´æº–ç¢ºçš„Jinja2è®Šæ•¸æª¢æ¸¬ï¼šæª¢æŸ¥æ˜¯å¦åŒ…å«çœŸæ­£çš„æ¨¡æ¿è®Šæ•¸
                    try:
                        from docx import Document
                        doc = Document(str(template_path))
                        all_text = ""
                        for para in doc.paragraphs:
                            all_text += para.text + "\n"
                        for table in doc.tables:
                            for row in table.rows:
                                for cell in row.cells:
                                    all_text += cell.text + "\n"
                        
                        # æª¢æŸ¥æ˜¯å¦åŒ…å«çœŸæ­£çš„Jinja2è®Šæ•¸ï¼ˆå­—æ¯æ•¸å­—çµ„åˆï¼‰
                        import re
                        jinja_pattern = r'\{\{\s*[a-zA-Z_][a-zA-Z0-9_.]*\s*\}\}'
                        has_jinja = bool(re.search(jinja_pattern, all_text))
                        logger.info(f"Template variable check (fallback): has_jinja={has_jinja}")
                        if has_jinja:
                            matches = re.findall(jinja_pattern, all_text)
                            logger.info(f"Found Jinja2 variables: {matches[:5]}")
                    except Exception as e:
                        logger.warning(f"Template variable check failed: {e}")
                        has_jinja = False
            except Exception as e:
                logger.warning(f"Template variable check failed: {e}")
                has_jinja = True

            if has_jinja:
                template = DocxTemplate(template_path)
                
                # æ·»åŠ èª¿è©¦ä¿¡æ¯
                logger.info(f"Starting Word template rendering: {template_path}")
                logger.info(f"Data structure: {list(data.keys())}")
                if 'æˆåˆ†è¡¨' in data:
                    logger.info(f"Ingredients data: {data['æˆåˆ†è¡¨'][:2] if isinstance(data['æˆåˆ†è¡¨'], list) and len(data['æˆåˆ†è¡¨']) > 0 else 'No ingredients data'}")
                
                # è½‰æ›è³‡æ–™çµæ§‹ä»¥åŒ¹é…æ¨¡æ¿æœŸæœ›çš„æ ¼å¼
                template_data = self._prepare_template_data(data)
                logger.info(f"Transformed data structure: {list(template_data.keys())}")
                
                try:
                    template.render(template_data)
                    template.save(output_path)
                    logger.info("Template rendering successful")
                except Exception as render_error:
                    logger.error(f"Template rendering failed: {render_error}")
                    # å˜—è©¦ä¿å­˜åŸå§‹æ¨¡æ¿ä½œç‚ºå‚™ä»½
                    import shutil
                    backup_path = output_path.with_suffix('.backup.docx')
                    shutil.copy2(template_path, backup_path)
                    logger.info(f"Original template backup saved: {backup_path}")
                    raise
                
                # Jinja2æ¸²æŸ“å¾Œï¼Œé‚„éœ€è¦é€²è¡Œæˆåˆ†è¡¨æ›¿æ›
                logger.info("Performing ingredient table replacement after Jinja2 rendering")
                self._replace_ingredients_tables_in_doc(output_path, data)
                
                # æ·»åŠ æ·ºè—åº•è‰²æ¨™è¨˜åˆ°æ’å…¥çš„è³‡æ–™
                self._highlight_inserted_data(output_path, data)
                
                logger.info(f"Word document generated: {output_path}")
                return True
            else:
                if not allow_fallback:
                    raise ValueError("æ¨¡æ¿ä¸å«è®Šæ•¸ä¸”æœªå…è¨±å›é€€æ›¿æ›æ¨¡å¼")
                # é—œéµè©æ›¿æ›æ¨¡å¼ï¼šä»¥ docx æ–‡æ®µéæ­·åšç°¡å–®è¦†å¯«ï¼ˆæ¨™ç±¤ï¼šå€¼ / [[key]] / <<key>> / {key}ï¼‰
                from docx import Document as DocxDocument
                doc = DocxDocument(str(template_path))

                # æ‰å¹³åŒ– data çš„éµï¼ˆa.b.c -> valueï¼‰
                flat: Dict[str, Any] = {}
                def flatten(prefix: str, obj: Any):
                    if isinstance(obj, dict):
                        for k, v in obj.items():
                            flatten(f"{prefix}.{k}" if prefix else k, v)
                    else:
                        flat[prefix] = obj
                flatten("", data)
                
                # ç‰¹åˆ¥è™•ç†æˆåˆ†è¡¨è³‡æ–™
                if 'æˆåˆ†è¡¨' in data and isinstance(data['æˆåˆ†è¡¨'], list):
                    logger.info(f"Processing ingredients data, {len(data['æˆåˆ†è¡¨'])} ingredients")
                    # ç‚ºæˆåˆ†è¡¨å‰µå»ºè¡¨æ ¼æ›¿æ›è³‡æ–™
                    flat['æˆåˆ†è¡¨_è¡¨æ ¼'] = self._create_ingredients_table(data['æˆåˆ†è¡¨'])

                # å¯åŒ¹é…çš„å ä½æ¨£å¼
                def variations(key: str) -> List[str]:
                    k = key
                    names = [k, k.split(".")[-1]]
                    outs = []
                    for n in names:
                        outs.extend([
                            f"[[{n}]]", f"<<{n}>>", f"{{{n}}}", f"ã€Š{n}ã€‹",
                            f"{n}ï¼š", f"{n}: "
                        ])
                    return outs

                # æ®µè½æ›¿æ›
                for p in doc.paragraphs:
                    text = p.text
                    new_text = text
                    for k, v in flat.items():
                        for token in variations(k):
                            if token.endswith('ï¼š') or token.endswith(': '):
                                # æ¨™ç±¤ï¼šå€¼ â†’ è¦†å¯«å¾Œæ–¹å…§å®¹
                                label = token.rstrip()
                                if label in new_text:
                                    # ç°¡å–®ç­–ç•¥ï¼šlabel ä¹‹å¾Œæ•´è¡Œæ›¿æ›ç‚º label + å€¼
                                    parts = new_text.split(label, 1)
                                    new_text = parts[0] + label + str(v)
                            else:
                                new_text = new_text.replace(token, str(v))
                    if new_text != text:
                        p.text = new_text

                # è¡¨æ ¼å„²å­˜æ ¼æ›¿æ›
                for table_idx, table in enumerate(doc.tables):
                    logger.info(f"Checking table {table_idx}, rows: {len(table.rows)}")
                    if table.rows:
                        first_row_text = " ".join([cell.text.strip() for cell in table.rows[0].cells]).lower()
                        logger.info(f"Table {table_idx} first row content: {first_row_text}")
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºæˆåˆ†è¡¨è¡¨æ ¼
                    if self._is_ingredients_table(table):
                        logger.info(f"Found ingredient table {table_idx}, performing replacement")
                        ingredients = self._extract_ingredients_from_data(data)
                        logger.info(f"Ingredients data: {ingredients}")
                        self._replace_ingredients_table(table, ingredients)
                    else:
                        # ä¸€èˆ¬è¡¨æ ¼æ›¿æ›
                        for row in table.rows:
                            for cell in row.cells:
                                txt = cell.text
                                new_txt = txt
                                for k, v in flat.items():
                                    for token in variations(k):
                                        if token.endswith('ï¼š') or token.endswith(': '):
                                            label = token.rstrip()
                                            if label in new_txt:
                                                parts = new_txt.split(label, 1)
                                                new_txt = parts[0] + label + str(v)
                                        else:
                                            new_txt = new_txt.replace(token, str(v))
                                if new_txt != txt:
                                    cell.text = new_txt

                doc.save(str(output_path))
                logger.info(f"Word document (keyword replacement mode) generated: {output_path}")
                
                # æ·»åŠ æ·ºè—åº•è‰²æ¨™è¨˜
                self._highlight_inserted_data(Path(output_path), data)
                
                return True

        except Exception as e:
            logger.error(f"Word conversion failed: {e}")
            # ç›´æ¥æ‹‹å‡ºç•°å¸¸ï¼Œä¸ä½¿ç”¨å›é€€æ©Ÿåˆ¶
            raise Exception(f"Wordè½‰æ›å¤±æ•—: {e}")
    
    def _prepare_template_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™æ¨¡æ¿è³‡æ–™ï¼Œç¢ºä¿è®Šæ•¸åç¨±åŒ¹é…"""
        # é¦–å…ˆè™•ç†åµŒå¥—çµæ§‹ï¼Œå°‡å…¶æ‰å¹³åŒ–ç‚ºProfileæœŸæœ›çš„æ ¼å¼
        flattened_data = self._flatten_nested_data(data)
        template_data = flattened_data.copy()
        
        # è™•ç†æˆåˆ†è¡¨è³‡æ–™çµæ§‹è½‰æ›
        if 'æˆåˆ†è¡¨' in template_data:
            # å¦‚æœæ¨¡æ¿æœŸæœ›çš„æ˜¯ æˆåˆ†.æˆåˆ†è¡¨ æ ¼å¼
            if 'æˆåˆ†' not in template_data:
                template_data['æˆåˆ†'] = {}
            template_data['æˆåˆ†']['æˆåˆ†è¡¨'] = template_data['æˆåˆ†è¡¨']
            
            # åŒæ™‚ä¿æŒåŸæœ‰çš„æˆåˆ†è¡¨æ ¼å¼
            # template_data['æˆåˆ†è¡¨'] = template_data['æˆåˆ†è¡¨']
        
        # è™•ç†å…¶ä»–å¯èƒ½çš„çµæ§‹è½‰æ›
        # åŸºæœ¬è³‡è¨Š
        if 'åŸºæœ¬è³‡è¨Š' in template_data:
            basic_info = template_data['åŸºæœ¬è³‡è¨Š']
            # å¦‚æœæ¨¡æ¿æœŸæœ›çš„æ˜¯ ç”¢å“åŸºæœ¬è³‡è¨Š æ ¼å¼
            if 'ç”¢å“åŸºæœ¬è³‡è¨Š' not in template_data:
                template_data['ç”¢å“åŸºæœ¬è³‡è¨Š'] = basic_info
        
        # è£½é€ è³‡è¨Š
        if 'è£½é€ è³‡è¨Š' in template_data:
            manufacturer_info = template_data['è£½é€ è³‡è¨Š']
            # å¦‚æœæ¨¡æ¿æœŸæœ›çš„æ˜¯ è£½é€ å•†è³‡è¨Š æ ¼å¼
            if 'è£½é€ å•†è³‡è¨Š' not in template_data:
                template_data['è£½é€ å•†è³‡è¨Š'] = manufacturer_info
        
        # å®‰å…¨è³‡è¨Š
        if 'å®‰å…¨è³‡è¨Š' in template_data:
            safety_info = template_data['å®‰å…¨è³‡è¨Š']
            # å¦‚æœæ¨¡æ¿æœŸæœ›çš„æ˜¯ å±å®³è³‡è¨Š æ ¼å¼
            if 'å±å®³è³‡è¨Š' not in template_data:
                template_data['å±å®³è³‡è¨Š'] = safety_info
        
        # ä½¿ç”¨æ–¹æ³•
        if 'ä½¿ç”¨æ–¹æ³•' in template_data:
            usage_info = template_data['ä½¿ç”¨æ–¹æ³•']
            # å¦‚æœæ¨¡æ¿æœŸæœ›çš„æ˜¯ ä½¿ç”¨èªªæ˜ æ ¼å¼
            if 'ä½¿ç”¨èªªæ˜' not in template_data:
                template_data['ä½¿ç”¨èªªæ˜'] = usage_info
        
        # å…¶ä»–è³‡è¨Š
        if 'å…¶ä»–è³‡è¨Š' in template_data:
            other_info = template_data['å…¶ä»–è³‡è¨Š']
            # å¦‚æœæ¨¡æ¿æœŸæœ›çš„æ˜¯ ç†åŒ–æ€§è³ª æ ¼å¼
            if 'ç†åŒ–æ€§è³ª' not in template_data:
                template_data['ç†åŒ–æ€§è³ª'] = other_info
        
        return template_data
    
    def _flatten_nested_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å°‡åµŒå¥—çš„JSONçµæ§‹æ‰å¹³åŒ–ç‚ºProfileæœŸæœ›çš„æ ¼å¼ - é€šç”¨ç‰ˆæœ¬"""
        flattened = {}
        
        # å®šç¾©æ¬„ä½æ˜ å°„è¦å‰‡ - æ”¯æ´å¤šç¨®å¯èƒ½çš„æ¬„ä½åç¨±
        field_mappings = {
            # ç”¢å“åŸºæœ¬è³‡è¨Šæ˜ å°„
            'ç”¢å“åç¨±': [
                'ç”¢å“åç¨±', 'product_name', 'name', 'title', 'ç”¢å“æ¨™é¡Œ',
                'åŸºæœ¬è³‡è¨Š.ç”¢å“åç¨±', 'ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç”¢å“åç¨±',
                'ç”¢å“åŸºæœ¬è³‡è¨Š.ç”¢å“åç¨±', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç”¢å“åç¨±'
            ],
            'ç”¢å“é¡åˆ¥': [
                'ç”¢å“é¡åˆ¥', 'product_category', 'category', 'type', 'ç”¢å“é¡å‹',
                'åŸºæœ¬è³‡è¨Š.ç”¢å“é¡åˆ¥', 'ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç”¢å“é¡å‹',
                'ç”¢å“åŸºæœ¬è³‡è¨Š.ç”¢å“é¡å‹', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç”¢å“é¡å‹'
            ],
            'ç”¢å“åŠ‘å‹': [
                'ç”¢å“åŠ‘å‹', 'product_form', 'form', 'åŠ‘å‹', 'ç‰©ç†å½¢æ…‹', 'ç‰©ç†ç‹€æ…‹',
                'åŸºæœ¬è³‡è¨Š.ç”¢å“åŠ‘å‹', 'ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç‰©ç†å½¢æ…‹',
                'ç”¢å“åŸºæœ¬è³‡è¨Š.ç”¢å“åŠ‘å‹', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.ç‰©ç†åŒ–å­¸ç‰¹æ€§.ç‰©ç†ç‹€æ…‹'
            ],
            'ç”¢å“ç”¨é€”': [
                'ç”¢å“ç”¨é€”', 'product_use', 'use', 'ç”¨é€”', 'intended_use',
                'åŸºæœ¬è³‡è¨Š.ç”¢å“ç”¨é€”', 'ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç”¢å“ç”¨é€”',
                'ç”¢å“åŸºæœ¬è³‡è¨Š.ç”¢å“ç”¨é€”', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.ç”¢å“ç”¨é€”'
            ],
            'å®¹é‡': [
                'å®¹é‡', 'volume', 'size', 'content', 'åŒ…è£å®¹é‡',
                'åŸºæœ¬è³‡è¨Š.å®¹é‡', 'ç”¢å“æª”æ¡ˆ.ç©©å®šæ€§èˆ‡åŒ…è£.å®¹é‡',
                'ç”¢å“åŸºæœ¬è³‡è¨Š.å®¹é‡', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.ç©©å®šæ€§èˆ‡åŒ…è£.å®¹é‡'
            ],
            'åŸç”¢åœ°': [
                'åŸç”¢åœ°', 'country_of_origin', 'origin', 'åŸç”¢åœ‹', 'ç”¢åœ°', 'country',
                'åŸºæœ¬è³‡è¨Š.åŸç”¢åœ°', 'ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.åŸç”¢åœ‹',
                'ç”¢å“åŸºæœ¬è³‡è¨Š.åŸç”¢åœ°', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.åŸºæœ¬è³‡è¨Š.åŸç”¢åœ‹',
                'result.product_info.basic.country', 'result.product_info.basic.origin'
            ],
            # è£½é€ å•†è³‡è¨Šæ˜ å°„
            'è£½é€ å•†åç¨±': [
                'è£½é€ å•†åç¨±', 'manufacturer_name', 'manufacturer', 'è£½é€ å•†', 'å…¬å¸åç¨±',
                'è£½é€ å•†è³‡è¨Š.å…¬å¸åç¨±', 'ç”¢å“æª”æ¡ˆ.è£½é€ å•†è³‡è¨Š.å…¬å¸åç¨±',
                'å» å•†èˆ‡è² è²¬äººè³‡è¨Š.è£½é€ å•†.åç¨±', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.è£½é€ å•†è³‡è¨Š.å…¬å¸åç¨±'
            ],
            'è£½é€ å•†åœ°å€': [
                'è£½é€ å•†åœ°å€', 'manufacturer_address', 'manufacturer_addr', 'åœ°å€',
                'è£½é€ å•†è³‡è¨Š.åœ°å€', 'ç”¢å“æª”æ¡ˆ.è£½é€ å•†è³‡è¨Š.åœ°å€',
                'å» å•†èˆ‡è² è²¬äººè³‡è¨Š.è£½é€ å•†.åœ°å€', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.è£½é€ å•†è³‡è¨Š.åœ°å€'
            ],
            'è£½é€ å•†è¯çµ¡æ–¹å¼': [
                'è£½é€ å•†è¯çµ¡æ–¹å¼', 'manufacturer_contact', 'manufacturer_phone', 'é›»è©±', 'è¯çµ¡æ–¹å¼',
                'è£½é€ å•†è³‡è¨Š.é›»è©±', 'ç”¢å“æª”æ¡ˆ.è£½é€ å•†è³‡è¨Š.é›»è©±',
                'å» å•†èˆ‡è² è²¬äººè³‡è¨Š.è£½é€ å•†.é›»è©±', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.è£½é€ å•†è³‡è¨Š.é›»è©±'
            ],
            # è¼¸å…¥å•†è³‡è¨Šæ˜ å°„
            'è¼¸å…¥å•†åç¨±': [
                'è¼¸å…¥å•†åç¨±', 'importer_name', 'importer', 'è¼¸å…¥å•†', 'è²¬ä»»äºº', 'æ­ç›Ÿè² è²¬äºº',
                'è²¬ä»»äººè³‡è¨Š.å…¬å¸åç¨±', 'ç”¢å“æª”æ¡ˆ.è²¬ä»»äººè³‡è¨Š.å…¬å¸åç¨±',
                'å» å•†èˆ‡è² è²¬äººè³‡è¨Š.æ­ç›Ÿè² è²¬äºº.åç¨±', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.è²¬ä»»äººè³‡è¨Š.å…¬å¸åç¨±'
            ],
            'è¼¸å…¥å•†åœ°å€': [
                'è¼¸å…¥å•†åœ°å€', 'importer_address', 'importer_addr',
                'è²¬ä»»äººè³‡è¨Š.åœ°å€', 'ç”¢å“æª”æ¡ˆ.è²¬ä»»äººè³‡è¨Š.åœ°å€',
                'å» å•†èˆ‡è² è²¬äººè³‡è¨Š.æ­ç›Ÿè² è²¬äºº.åœ°å€', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.è²¬ä»»äººè³‡è¨Š.åœ°å€'
            ],
            'è¼¸å…¥å•†é›»è©±': [
                'è¼¸å…¥å•†é›»è©±', 'importer_phone', 'importer_contact',
                'è²¬ä»»äººè³‡è¨Š.é›»è©±', 'ç”¢å“æª”æ¡ˆ.è²¬ä»»äººè³‡è¨Š.é›»è©±',
                'å» å•†èˆ‡è² è²¬äººè³‡è¨Š.æ­ç›Ÿè² è²¬äºº.é›»è©±', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.è²¬ä»»äººè³‡è¨Š.é›»è©±'
            ],
            # æˆåˆ†è¡¨æ˜ å°„
            'æˆåˆ†è¡¨': [
                'æˆåˆ†è¡¨', 'ingredients', 'ingredient_list', 'æˆåˆ†', 'å®Œæ•´æˆåˆ†è¡¨', 'å®Œæ•´æˆåˆ†è¡¨(INCI)',
                'ä¸»è¦æˆåˆ†', 'æˆåˆ†è³‡è¨Š', 'ingredient_info', 'composition'
            ],
            # å…¶ä»–è³‡è¨Šæ˜ å°„
            'æœ‰æ•ˆæœŸé™': [
                'æœ‰æ•ˆæœŸé™', 'expiry_date', 'shelf_life', 'ä¿è³ªæœŸ', 'ç”¢å“ä¿è³ªæœŸ', 'é–‹å°å¾Œä¿è³ªæœŸ(PAO)',
                'ç©©å®šæ€§èˆ‡åŒ…è£.ç”¢å“ä¿è³ªæœŸ', 'ç”¢å“æª”æ¡ˆ.ç©©å®šæ€§èˆ‡åŒ…è£.ç”¢å“ä¿è³ªæœŸ',
                'ç©©å®šæ€§èˆ‡å„²å­˜.æœ€çŸ­ä¿è³ªæœŸ', 'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.ç©©å®šæ€§èˆ‡åŒ…è£.ç”¢å“ä¿è³ªæœŸ'
            ],
            'å®‰å…¨è©•ä¼°çµæœ': [
                'å®‰å…¨è©•ä¼°çµæœ', 'safety_assessment', 'safety_evaluation', 'å®‰å…¨è©•ä¼°çµè«–',
                'å®‰å…¨è³‡è¨Š.å®‰å…¨è©•ä¼°çµè«–', 'ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.å®‰å…¨è©•ä¼°çµè«–',
                'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.å®‰å…¨è©•ä¼°çµè«–'
            ],
            'æˆåˆ†å®‰å…¨æ€§': [
                'æˆåˆ†å®‰å…¨æ€§', 'ingredient_safety', 'safety_info',
                'å®‰å…¨è³‡è¨Š.æˆåˆ†å®‰å…¨æ€§', 'ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.æˆåˆ†å®‰å…¨æ€§',
                'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.æˆåˆ†å®‰å…¨æ€§'
            ],
            'ä½¿ç”¨é™åˆ¶': [
                'ä½¿ç”¨é™åˆ¶', 'usage_restrictions', 'restrictions', 'ä½¿ç”¨é™åˆ¶å’Œç¦å¿Œ',
                'å®‰å…¨è³‡è¨Š.ä½¿ç”¨é™åˆ¶', 'ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.ä½¿ç”¨é™åˆ¶',
                'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.ä½¿ç”¨é™åˆ¶'
            ],
            'ä½¿ç”¨æ–¹å¼': [
                'ä½¿ç”¨æ–¹å¼', 'usage_method', 'how_to_use', 'ä½¿ç”¨æ–¹æ³•', 'ä½¿ç”¨æ³¨æ„äº‹é …',
                'å®‰å…¨è³‡è¨Š.æ¨™ç±¤è­¦èª.ä½¿ç”¨æ³¨æ„äº‹é …', 'ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.æ¨™ç±¤è­¦èª.ä½¿ç”¨æ³¨æ„äº‹é …',
                'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.æ¨™ç±¤è­¦èª.ä½¿ç”¨æ³¨æ„äº‹é …'
            ],
            'æ³¨æ„äº‹é …': [
                'æ³¨æ„äº‹é …', 'precautions', 'warnings', 'ä½¿ç”¨æ³¨æ„äº‹é …',
                'å®‰å…¨è³‡è¨Š.æ¨™ç±¤è­¦èª.ä½¿ç”¨æ³¨æ„äº‹é …', 'ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.æ¨™ç±¤è­¦èª.ä½¿ç”¨æ³¨æ„äº‹é …',
                'è™•ç†çµæœ.ç”¢å“æª”æ¡ˆ.å®‰å…¨è³‡è¨Š.æ¨™ç±¤è­¦èª.ä½¿ç”¨æ³¨æ„äº‹é …'
            ],
            'ä½¿ç”¨éƒ¨ä½': [
                'ä½¿ç”¨éƒ¨ä½', 'application_site', 'where_to_use', 'é©ç”¨éƒ¨ä½'
            ]
        }
        
        # éæ­¸æœå°‹ä¸¦æå–æ¬„ä½å€¼
        def extract_field_value(data: Dict[str, Any], field_paths: List[str]) -> Any:
            """éæ­¸æœå°‹æ¬„ä½å€¼"""
            for path in field_paths:
                try:
                    # è™•ç†é»è™Ÿåˆ†éš”çš„åµŒå¥—è·¯å¾‘
                    if '.' in path:
                        keys = path.split('.')
                        current_data = data
                        for key in keys:
                            if isinstance(current_data, dict) and key in current_data:
                                current_data = current_data[key]
                            else:
                                current_data = None
                                break
                        if current_data is not None:
                            return current_data
                    # è™•ç†ç›´æ¥æ¬„ä½åç¨±
                    elif path in data:
                        return data[path]
                except (KeyError, TypeError, AttributeError):
                    continue
            return None
        
        # éæ­¸æœå°‹æ‰€æœ‰åµŒå¥—çµæ§‹
        def recursive_search(data: Dict[str, Any], target_field: str) -> Any:
            """éæ­¸æœå°‹ç›®æ¨™æ¬„ä½"""
            if target_field in data:
                return data[target_field]
            
            for key, value in data.items():
                if isinstance(value, dict):
                    result = recursive_search(value, target_field)
                    if result is not None:
                        return result
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, dict):
                            result = recursive_search(item, target_field)
                            if result is not None:
                                return result
            
            return None
        
        # æ‡‰ç”¨æ¬„ä½æ˜ å°„
        for target_field, possible_paths in field_mappings.items():
            value = None
            
            # é¦–å…ˆå˜—è©¦ç›´æ¥è·¯å¾‘æœå°‹
            value = extract_field_value(data, possible_paths)
            
            # å¦‚æœæ²’æ‰¾åˆ°ï¼Œå˜—è©¦éæ­¸æœå°‹
            if value is None:
                for path in possible_paths:
                    if '.' not in path:  # åªå°ç°¡å–®æ¬„ä½åç¨±é€²è¡Œéæ­¸æœå°‹
                        value = recursive_search(data, path)
                        if value is not None:
                            break
            
            if value is not None:
                flattened[target_field] = value
        
        # ä¿ç•™åŸå§‹è³‡æ–™ä¸­çš„å…¶ä»–æ¬„ä½ï¼ˆéç³»çµ±æ¬„ä½ï¼‰
        system_fields = ['_raw_response', 'è™•ç†çµæœ']
        for key, value in data.items():
            if key not in system_fields and key not in flattened:
                flattened[key] = value
        
        logger.info(f"ğŸ”§ Flattened fields: {list(flattened.keys())}")
        logger.info(f"ğŸ”§ Ingredients field exists: {'æˆåˆ†è¡¨' in flattened}")
        if 'æˆåˆ†è¡¨' in flattened:
            logger.info(f"ğŸ”§ Ingredients type: {type(flattened['æˆåˆ†è¡¨'])}")
            if isinstance(flattened['æˆåˆ†è¡¨'], list):
                logger.info(f"ğŸ”§ Ingredients length: {len(flattened['æˆåˆ†è¡¨'])}")
        
        return flattened
    
    def _create_ingredients_table(self, ingredients: List[Dict[str, Any]]) -> str:
        """å‰µå»ºæˆåˆ†è¡¨è¡¨æ ¼å­—ä¸²"""
        if not ingredients:
            return ""
        
        # å‰µå»ºè¡¨æ ¼æ¨™é¡Œè¡Œ
        table_lines = ["INCI Name\tCas. No\tW/V%\tåŠŸèƒ½"]
        
        # æ·»åŠ æˆåˆ†è³‡æ–™è¡Œ
        for ingredient in ingredients:
            inci_name = ingredient.get('INCIåç¨±', '')
            cas_number = ingredient.get('CASè™Ÿç¢¼', '') or '-'
            content = ingredient.get('å«é‡', '')
            function = ingredient.get('åŠŸèƒ½', '')
            
            table_lines.append(f"{inci_name}\t{cas_number}\t{content}\t{function}")
        
        return "\n".join(table_lines)
    
    def _is_ingredients_table(self, table) -> bool:
        """æª¢æŸ¥è¡¨æ ¼æ˜¯å¦ç‚ºæˆåˆ†è¡¨"""
        if not table.rows:
            return False
        
        # æª¢æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦åŒ…å«æˆåˆ†è¡¨æ¨™é¡Œ
        first_row = table.rows[0]
        first_row_text = " ".join([cell.text.strip() for cell in first_row.cells]).lower()
        
        ingredients_keywords = ['inci', 'cas', 'w/v', 'åŠŸèƒ½', 'ingredient', 'content']
        return any(keyword in first_row_text for keyword in ingredients_keywords)
    
    def _extract_ingredients_from_data(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å¾æ•¸æ“šä¸­æå–æˆåˆ†è¡¨è³‡è¨Šï¼Œæ”¯æ´å¤šç¨®æ ¼å¼"""
        ingredients = []
        
        # æ·»åŠ èª¿è©¦æ—¥èªŒ
        logger.info(f"ğŸ” Starting ingredient extraction, data structure: {list(data.keys())}")
        logger.info(f"ğŸ” Original response length: {len(data.get('_raw_response', ''))}")
        
        # 1. å˜—è©¦å¾Profileå®šç¾©çš„æˆåˆ†è¡¨æ¬„ä½æå–
        ingredient_field_names = []
        
        # å¾Profileä¸­å°‹æ‰¾å¯èƒ½çš„æˆåˆ†è¡¨æ¬„ä½
        for field_name, field_info in self.profile_fields.items():
            if any(keyword in field_name.lower() for keyword in ['æˆåˆ†', 'ingredient', 'å…¨æˆåˆ†']):
                ingredient_field_names.append(field_name)
                logger.info(f"ğŸ” Found possible ingredient field: {field_name}")
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é è¨­çš„æ¬„ä½åç¨±
        if not ingredient_field_names:
            ingredient_field_names = ['æˆåˆ†è¡¨', 'å…¨æˆåˆ†è¡¨', 'ingredients']
            logger.info("ğŸ” ä½¿ç”¨é è¨­æˆåˆ†è¡¨æ¬„ä½åç¨±")
        
        # å˜—è©¦å¾æ‰¾åˆ°çš„æ¬„ä½ä¸­æå–æˆåˆ†
        for field_name in ingredient_field_names:
            # é¦–å…ˆå˜—è©¦åœ¨æ ¹å±¤ç´šå°‹æ‰¾
            if field_name in data and data[field_name]:
                logger.info(f"ğŸ” åœ¨æ ¹å±¤ç´šæ‰¾åˆ°æˆåˆ†è¡¨æ¬„ä½ '{field_name}': {type(data[field_name])}")
                ingredients_found = self._extract_ingredients_from_field(data[field_name], field_name)
                if ingredients_found:
                    ingredients.extend(ingredients_found)
                    logger.info(f"âœ… å¾æ ¹å±¤ç´šæå–åˆ° {len(ingredients_found)} å€‹æˆåˆ†")
                    break
            # å¦‚æœæ ¹å±¤ç´šæ²’æœ‰ï¼Œå˜—è©¦åœ¨ 'data' å­ç‰©ä»¶ä¸­å°‹æ‰¾
            elif 'data' in data and isinstance(data['data'], dict) and field_name in data['data'] and data['data'][field_name]:
                logger.info(f"ğŸ” åœ¨dataå­ç‰©ä»¶ä¸­æ‰¾åˆ°æˆåˆ†è¡¨æ¬„ä½ '{field_name}': {type(data['data'][field_name])}")
                ingredients_found = self._extract_ingredients_from_field(data['data'][field_name], field_name)
                if ingredients_found:
                    ingredients.extend(ingredients_found)
                    logger.info(f"âœ… å¾dataå­ç‰©ä»¶æå–åˆ° {len(ingredients_found)} å€‹æˆåˆ†")
                    break
        else:
            logger.warning(f"âŒ æœªæ‰¾åˆ°æˆåˆ†è¡¨æ¬„ä½ï¼Œå˜—è©¦çš„æ¬„ä½åç¨±: {ingredient_field_names}")
            logger.info(f"ğŸ” æ•¸æ“šçµæ§‹: {list(data.keys())}")
            if 'data' in data and isinstance(data['data'], dict):
                logger.info(f"ğŸ” dataå­ç‰©ä»¶çµæ§‹: {list(data['data'].keys())}")
        
        # 2. å˜—è©¦å¾ä¸»è¦æˆåˆ†æ¬„ä½æå–
        if 'ä¸»è¦æˆåˆ†' in data and data['ä¸»è¦æˆåˆ†']:
            logger.info(f"ğŸ” æ‰¾åˆ°ä¸»è¦æˆåˆ†æ¬„ä½: {type(data['ä¸»è¦æˆåˆ†'])}")
            main_ingredients = data['ä¸»è¦æˆåˆ†']
            if isinstance(main_ingredients, str):
                # å¦‚æœæ˜¯å­—ä¸²ï¼Œå˜—è©¦è§£æ
                ingredients.append({
                    'INCIåç¨±': main_ingredients,
                    'CASè™Ÿç¢¼': '',
                    'å«é‡': '',
                    'åŠŸèƒ½': ''
                })
                logger.info(f"âœ… æ·»åŠ ä¸»è¦æˆåˆ†å­—ä¸²: {main_ingredients[:50]}...")
            elif isinstance(main_ingredients, list):
                logger.info(f"ğŸ” ä¸»è¦æˆåˆ†åˆ—è¡¨é•·åº¦: {len(main_ingredients)}")
                for i, ingredient in enumerate(main_ingredients):
                    if isinstance(ingredient, str):
                        ingredients.append({
                            'INCIåç¨±': ingredient,
                            'CASè™Ÿç¢¼': '',
                            'å«é‡': '',
                            'åŠŸèƒ½': ''
                        })
                        logger.info(f"âœ… æ·»åŠ ä¸»è¦æˆåˆ† {i+1}: {ingredient[:50]}...")
        else:
            logger.info("â„¹ï¸ æœªæ‰¾åˆ°ä¸»è¦æˆåˆ†æ¬„ä½")
        
        # 3. å˜—è©¦å¾åŸå§‹éŸ¿æ‡‰ä¸­æå– Markdown è¡¨æ ¼
        raw_response = data.get('_raw_response', '')
        if raw_response and '|' in raw_response:
            logger.info(f"ğŸ” åŸå§‹éŸ¿æ‡‰åŒ…å«Markdownè¡¨æ ¼æ¨™è¨˜ï¼Œé•·åº¦: {len(raw_response)}")
            markdown_ingredients = self._parse_markdown_ingredients_table(raw_response)
            ingredients.extend(markdown_ingredients)
            logger.info(f"âœ… å¾Markdownè¡¨æ ¼æå–åˆ° {len(markdown_ingredients)} å€‹æˆåˆ†")
        else:
            logger.info("â„¹ï¸ åŸå§‹éŸ¿æ‡‰ä¸åŒ…å«Markdownè¡¨æ ¼æ¨™è¨˜")
        
        # 4. æª¢æŸ¥å…¶ä»–å¯èƒ½çš„æˆåˆ†æ¬„ä½ï¼ˆå¢å¼·é€šç”¨æ€§ï¼‰
        possible_ingredient_fields = [
            'ingredients', 'æˆåˆ†', 'ingredient_list', 'composition',
            'ingredient', 'ingredients_list', 'ingredient_table',
            'æˆåˆ†åˆ—è¡¨', 'æˆåˆ†è¡¨', 'ä¸»è¦æˆåˆ†', 'æˆåˆ†è³‡è¨Š', 'å®Œæ•´æˆåˆ†è¡¨',
            'ingredient_info', 'composition_list', 'ingredient_data',
            'ingredients_data', 'ingredient_details', 'composition_details',
            'æ¨™ç±¤æˆåˆ†åˆ—è¡¨', 'æˆåˆ†æ¸…å–®', 'ingredient_composition'
        ]
        
        for field in possible_ingredient_fields:
            if field in data and data[field]:
                logger.info(f"ğŸ” æ‰¾åˆ°å¯èƒ½çš„æˆåˆ†æ¬„ä½ '{field}': {type(data[field])}")
                # å˜—è©¦å¾é€™å€‹æ¬„ä½æå–æˆåˆ†
                if isinstance(data[field], list):
                    logger.info(f"ğŸ” æ¬„ä½ '{field}' æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œé•·åº¦: {len(data[field])}")
                    for i, item in enumerate(data[field]):
                        if isinstance(item, dict):
                            # æª¢æŸ¥æ˜¯å¦åŒ…å«æˆåˆ†ç›¸é—œçš„éµ
                            if any(key in item for key in ['INCIåç¨±', 'inci_name', 'name', 'æˆåˆ†åç¨±', 'ingredient_name']):
                                # æ¨™æº–åŒ–æ¬„ä½åç¨±
                                standardized_item = self._standardize_ingredient_fields(item)
                                ingredients.append(standardized_item)
                                logger.info(f"âœ… å¾æ¬„ä½ '{field}' æ·»åŠ æˆåˆ† {i+1}: {standardized_item.get('INCIåç¨±', 'Unknown')}")
                        elif isinstance(item, str) and len(item.strip()) > 0:
                            # å˜—è©¦è§£æå­—ä¸²æ ¼å¼çš„æˆåˆ†
                            parsed_ingredient = self._parse_ingredient_string(item)
                            if parsed_ingredient:
                                ingredients.append(parsed_ingredient)
                                logger.info(f"âœ… å¾æ¬„ä½ '{field}' è§£ææˆåˆ† {i+1}: {parsed_ingredient.get('INCIåç¨±', 'Unknown')}")
                elif isinstance(data[field], str) and len(data[field].strip()) > 0:
                    logger.info(f"ğŸ” æ¬„ä½ '{field}' æ˜¯å­—ä¸²æ ¼å¼")
                    # å˜—è©¦è§£æå­—ä¸²æ ¼å¼çš„æˆåˆ†
                    parsed_ingredient = self._parse_ingredient_string(data[field])
                    if parsed_ingredient:
                        ingredients.append(parsed_ingredient)
                        logger.info(f"âœ… å¾æ¬„ä½ '{field}' è§£ææˆåˆ†: {parsed_ingredient.get('INCIåç¨±', 'Unknown')}")
        
        logger.info(f"ğŸ¯ æœ€çµ‚æå–åˆ° {len(ingredients)} å€‹æˆåˆ†")
        return ingredients
    
    def _standardize_ingredient_fields(self, ingredient: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨™æº–åŒ–æˆåˆ†æ¬„ä½åç¨±ï¼Œç¢ºä¿èˆ‡æ¨¡æ¿æœŸæœ›çš„æ ¼å¼ä¸€è‡´"""
        standardized = {}
        
        # åç¨±æ¬„ä½æ˜ å°„
        name_fields = ['INCIåç¨±', 'inci_name', 'name', 'æˆåˆ†åç¨±', 'ingredient_name', 'æˆåˆ†åç¨±']
        for field in name_fields:
            if field in ingredient:
                standardized['INCIåç¨±'] = ingredient[field]
                break
        
        # CASè™Ÿç¢¼æ¬„ä½æ˜ å°„
        cas_fields = ['CASè™Ÿç¢¼', 'cas_number', 'cas', 'CAS', 'cas_no']
        for field in cas_fields:
            if field in ingredient:
                standardized['CASè™Ÿç¢¼'] = ingredient[field]
                break
        
        # å«é‡æ¬„ä½æ˜ å°„
        content_fields = ['å«é‡', 'content', 'percentage', 'ç™¾åˆ†æ¯”', 'concentration', 'w/v%']
        for field in content_fields:
            if field in ingredient:
                standardized['å«é‡'] = ingredient[field]
                break
        
        # åŠŸèƒ½æ¬„ä½æ˜ å°„
        function_fields = ['åŠŸèƒ½', 'function', 'purpose', 'åŠŸèƒ½èªªæ˜', 'role']
        for field in function_fields:
            if field in ingredient:
                standardized['åŠŸèƒ½'] = ingredient[field]
                break
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™æº–æ¬„ä½ï¼Œä¿ç•™åŸå§‹æ¬„ä½
        if not standardized:
            standardized = ingredient.copy()
        
        logger.info(f"ğŸ”§ æ¨™æº–åŒ–æˆåˆ†æ¬„ä½: {list(standardized.keys())}")
        return standardized
    
    def _parse_ingredient_string(self, ingredient_str: str) -> Dict[str, Any]:
        """è§£ææˆåˆ†å­—ä¸²æ ¼å¼"""
        try:
            # æ ¼å¼ï¼šAlcohol denat. (CAS: 64-17-5, å«é‡: 76.80000%, åŠŸèƒ½: æŠ—æ³¡åŠ‘ã€æŠ—èŒåŠ‘ã€æ”¶æ–‚åŠ‘ã€é®è”½åŠ‘ã€æº¶åŠ‘ã€é»åº¦æ§åˆ¶åŠ‘)
            import re
            
            # æå–INCIåç¨±ï¼ˆæ‹¬è™Ÿå‰çš„éƒ¨åˆ†ï¼‰
            inci_match = re.match(r'^([^(]+)', ingredient_str.strip())
            if not inci_match:
                return None
            
            inci_name = inci_match.group(1).strip()
            
            # æå–CASè™Ÿç¢¼
            cas_match = re.search(r'CAS:\s*([^,)]+)', ingredient_str)
            cas_number = cas_match.group(1).strip() if cas_match else ''
            
            # æå–å«é‡
            content_match = re.search(r'å«é‡:\s*([^,)]+)', ingredient_str)
            content = content_match.group(1).strip() if content_match else ''
            
            # æå–åŠŸèƒ½
            function_match = re.search(r'åŠŸèƒ½:\s*([^)]+)', ingredient_str)
            function = function_match.group(1).strip() if function_match else ''
            
            return {
                'INCIåç¨±': inci_name,
                'CASè™Ÿç¢¼': cas_number,
                'å«é‡': content,
                'åŠŸèƒ½': function
            }
            
        except Exception as e:
            logger.warning(f"è§£ææˆåˆ†å­—ä¸²å¤±æ•—: {ingredient_str}, éŒ¯èª¤: {e}")
            return None
    
    def _extract_ingredients_from_field(self, field_data: Any, field_name: str) -> List[Dict[str, Any]]:
        """å¾æˆåˆ†è¡¨æ¬„ä½ä¸­æå–æˆåˆ†"""
        ingredients = []
        
        if isinstance(field_data, list):
            logger.info(f"ğŸ” æˆåˆ†è¡¨åˆ—è¡¨é•·åº¦: {len(field_data)}")
            for i, ingredient in enumerate(field_data):
                logger.info(f"ğŸ” æˆåˆ† {i+1}: {type(ingredient)} - {str(ingredient)[:100]}...")
                if isinstance(ingredient, dict):
                    # å·²ç¶“æ˜¯å­—å…¸æ ¼å¼ï¼Œç›´æ¥æ·»åŠ 
                    ingredients.append(ingredient)
                    logger.info(f"âœ… æ·»åŠ å­—å…¸æ ¼å¼æˆåˆ†: {ingredient.get('INCIåç¨±', 'Unknown')}")
                elif isinstance(ingredient, str):
                    # å­—ä¸²æ ¼å¼ï¼Œéœ€è¦è§£æ
                    parsed_ingredient = self._parse_ingredient_string(ingredient)
                    if parsed_ingredient:
                        ingredients.append(parsed_ingredient)
                        logger.info(f"âœ… è§£æå­—ä¸²æ ¼å¼æˆåˆ†: {parsed_ingredient.get('INCIåç¨±', 'Unknown')}")
                    else:
                        logger.warning(f"âŒ å­—ä¸²æ ¼å¼æˆåˆ†è§£æå¤±æ•—: {ingredient[:50]}...")
        elif isinstance(field_data, str):
            # å­—ä¸²æ ¼å¼çš„æˆåˆ†è¡¨ï¼Œå˜—è©¦è§£æ
            logger.info(f"ğŸ” æˆåˆ†è¡¨ç‚ºå­—ä¸²æ ¼å¼ï¼Œé•·åº¦: {len(field_data)}")
            parsed_ingredients = self._parse_tab_separated_ingredients(field_data)
            if parsed_ingredients:
                ingredients.extend(parsed_ingredients)
                logger.info(f"âœ… è§£æTabåˆ†éš”æˆåˆ†è¡¨ï¼Œå…± {len(parsed_ingredients)} å€‹æˆåˆ†")
            else:
                logger.warning(f"âŒ Tabåˆ†éš”æˆåˆ†è¡¨è§£æå¤±æ•—")
        else:
            logger.warning(f"âŒ æˆåˆ†è¡¨æ¬„ä½ä¸æ˜¯åˆ—è¡¨æˆ–å­—ä¸²æ ¼å¼: {type(field_data)}")
        
        return ingredients
    
    def _parse_tab_separated_ingredients(self, ingredient_table_str: str) -> List[Dict[str, Any]]:
        """è§£æTabåˆ†éš”çš„æˆåˆ†è¡¨æ ¼å¼"""
        try:
            ingredients = []
            lines = ingredient_table_str.strip().split('\n')
            
            if len(lines) < 2:
                logger.warning("æˆåˆ†è¡¨æ ¼å¼ä¸æ­£ç¢ºï¼Œè‡³å°‘éœ€è¦æ¨™é¡Œè¡Œå’Œæ•¸æ“šè¡Œ")
                return []
            
            # ç¬¬ä¸€è¡Œæ˜¯æ¨™é¡Œè¡Œ
            header_line = lines[0]
            headers = [h.strip() for h in header_line.split('\t')]
            logger.info(f"ğŸ” æˆåˆ†è¡¨æ¨™é¡Œ: {headers}")
            
            # è™•ç†æ•¸æ“šè¡Œ
            for i, line in enumerate(lines[1:], 1):
                if not line.strip():
                    continue
                
                parts = [p.strip() for p in line.split('\t')]
                if len(parts) < len(headers):
                    logger.warning(f"ç¬¬ {i} è¡Œæ•¸æ“šä¸å®Œæ•´: {line}")
                    continue
                
                # å‰µå»ºæˆåˆ†å­—å…¸
                ingredient = {}
                for j, header in enumerate(headers):
                    if j < len(parts):
                        # å°‡æ¨™é¡Œæ˜ å°„åˆ°æ¨™æº–æ¬„ä½åç¨±
                        if 'inci' in header.lower() or 'åç¨±' in header:
                            ingredient['INCIåç¨±'] = parts[j]
                        elif 'cas' in header.lower() or 'è™Ÿç¢¼' in header:
                            ingredient['CASè™Ÿç¢¼'] = parts[j]
                        elif 'w/v' in header.lower() or 'å«é‡' in header or '%' in header:
                            ingredient['å«é‡'] = parts[j]
                        elif 'åŠŸèƒ½' in header.lower() or 'function' in header.lower():
                            ingredient['åŠŸèƒ½'] = parts[j]
                        else:
                            # ä½¿ç”¨åŸå§‹æ¨™é¡Œä½œç‚ºéµå
                            ingredient[header] = parts[j]
                
                if ingredient:
                    ingredients.append(ingredient)
                    logger.debug(f"âœ… è§£ææˆåˆ† {i}: {ingredient.get('INCIåç¨±', 'Unknown')}")
            
            logger.info(f"âœ… æˆåŠŸè§£æTabåˆ†éš”æˆåˆ†è¡¨ï¼Œå…± {len(ingredients)} å€‹æˆåˆ†")
            return ingredients
            
        except Exception as e:
            logger.error(f"è§£æTabåˆ†éš”æˆåˆ†è¡¨å¤±æ•—: {e}")
            return []
    
    def _parse_markdown_ingredients_table(self, text: str) -> List[Dict[str, Any]]:
        """è§£æ Markdown æ ¼å¼çš„æˆåˆ†è¡¨"""
        ingredients = []
        lines = text.split('\n')
        
        in_table = False
        headers = []
        
        for line in lines:
            line = line.strip()
            
            # æª¢æ¸¬è¡¨æ ¼é–‹å§‹ï¼ˆå¿…é ˆæ˜¯è¡¨é ­è¡Œï¼‰
            if '|' in line and ('æˆåˆ†' in line or 'inci' in line.lower() or 'åºè™Ÿ' in line) and not in_table:
                in_table = True
                # è§£æè¡¨é ­
                headers = [h.strip() for h in line.split('|') if h.strip()]
                continue
            
            # æª¢æ¸¬è¡¨æ ¼çµæŸï¼ˆåˆ†éš”è¡Œï¼‰
            if in_table and line.startswith('|') and line.count('-') >= 3:
                continue
            
            # è§£æè¡¨æ ¼è¡Œ
            if in_table and line.startswith('|') and not line.startswith('|---'):
                # åˆ†å‰²è¡¨æ ¼è¡Œï¼Œä¿ç•™ç©ºå­—ä¸²
                raw_cells = line.split('|')
                # ç§»é™¤é¦–å°¾çš„ç©ºå­—ä¸²ï¼Œä½†ä¿ç•™ä¸­é–“çš„ç©ºå­—ä¸²
                if raw_cells and not raw_cells[0].strip():
                    raw_cells = raw_cells[1:]
                if raw_cells and not raw_cells[-1].strip():
                    raw_cells = raw_cells[:-1]
                cells = [c.strip() for c in raw_cells]
                if len(cells) >= 2:  # è‡³å°‘è¦æœ‰æˆåˆ†åç¨±
                    ingredient = {}
                    for i, cell in enumerate(cells):
                        if i < len(headers):
                            header = headers[i].lower()
                            if 'æˆåˆ†' in header or 'name' in header:
                                ingredient['INCIåç¨±'] = cell
                            elif 'cas' in header:
                                ingredient['CASè™Ÿç¢¼'] = cell
                            elif 'å«é‡' in header or 'content' in header or 'w/v' in header:
                                ingredient['å«é‡'] = cell
                            elif 'åŠŸèƒ½' in header or 'function' in header or 'èªªæ˜' in header:
                                ingredient['åŠŸèƒ½'] = cell
                    
                    # ç¢ºä¿æœ‰æˆåˆ†åç¨±æ‰æ·»åŠ 
                    if ingredient.get('INCIåç¨±') and ingredient['INCIåç¨±'] != 'æˆåˆ†åç¨±':
                        ingredients.append(ingredient)
        
        return ingredients
    
    def _replace_ingredients_table(self, table, ingredients: List[Dict[str, Any]]) -> None:
        """æ›¿æ›æˆåˆ†è¡¨è¡¨æ ¼å…§å®¹"""
        if not ingredients:
            return
        
        # ä¿å­˜ç¬¬ä¸€è¡Œçš„æ ¼å¼ä½œç‚ºæ¨¡æ¿
        format_template = None
        if len(table.rows) > 0:
            format_template = []
            for cell in table.rows[0].cells:
                cell_formats = []
                for paragraph in cell.paragraphs:
                    for run in paragraph.runs:
                        cell_formats.append({
                            'font_name': run.font.name,
                            'font_size': run.font.size,
                            'bold': run.bold,
                            'italic': run.italic,
                            'underline': run.underline
                        })
                format_template.append(cell_formats)
        
        # æ¸…ç©ºç¾æœ‰è¡¨æ ¼å…§å®¹ï¼ˆä¿ç•™ç¬¬ä¸€è¡Œæ¨™é¡Œï¼‰
        if len(table.rows) > 1:
            # åˆªé™¤é™¤ç¬¬ä¸€è¡Œå¤–çš„æ‰€æœ‰è¡Œ
            for i in range(len(table.rows) - 1, 0, -1):
                table._element.remove(table.rows[i]._element)
        
        # æ·»åŠ æ–°çš„æˆåˆ†è³‡æ–™è¡Œ
        for ingredient in ingredients:
            new_row = table.add_row()
            cells = new_row.cells
            
            if len(cells) >= 4:
                # æ›¿æ›å…§å®¹ä¸¦ä¿æŒæ ¼å¼
                ingredient_data = [
                    ingredient.get('INCIåç¨±', ''),
                    ingredient.get('CASè™Ÿç¢¼', '') or '-',
                    ingredient.get('å«é‡', ''),
                    ingredient.get('åŠŸèƒ½', '')
                ]
                
                for i, (cell, content) in enumerate(zip(cells, ingredient_data)):
                    # æ¸…ç©ºç¾æœ‰å…§å®¹
                    for paragraph in cell.paragraphs:
                        for run in paragraph.runs:
                            run.text = ""
                    
                    # æ·»åŠ æ–°å…§å®¹
                    if cell.paragraphs:
                        run = cell.paragraphs[0].runs[0] if cell.paragraphs[0].runs else cell.paragraphs[0].add_run()
                        run.text = content
                        
                        # æ‡‰ç”¨æ ¼å¼æ¨¡æ¿ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if format_template and i < len(format_template) and format_template[i]:
                            template = format_template[i][0]  # ä½¿ç”¨ç¬¬ä¸€å€‹runçš„æ ¼å¼
                            if template['font_name']:
                                run.font.name = template['font_name']
                            if template['font_size']:
                                run.font.size = template['font_size']
                            if template['bold'] is not None:
                                run.bold = template['bold']
                            if template['italic'] is not None:
                                run.italic = template['italic']
                            if template['underline'] is not None:
                                run.underline = template['underline']
                        
                        # æ·»åŠ æ·ºè—è‰²èƒŒæ™¯æ¨™è¨˜
                        try:
                            from docx.oxml import OxmlElement
                            shading = OxmlElement('w:shd')
                            shading.set(qn('w:val'), 'clear')
                            shading.set(qn('w:color'), 'auto')
                            shading.set(qn('w:fill'), 'B4D4E6')
                            run._element.get_or_add_rPr().append(shading)
                        except Exception as e:
                            logger.warning(f"æ·»åŠ èƒŒæ™¯æ¨™è¨˜å¤±æ•—: {e}")
    
    def _replace_ingredients_tables_in_doc(self, doc_path: Path, data: Dict[str, Any]) -> None:
        """åœ¨Wordæ–‡æª”ä¸­æ›¿æ›æ‰€æœ‰æˆåˆ†è¡¨è¡¨æ ¼"""
        try:
            from docx import Document
            doc = Document(str(doc_path))
            
            ingredients = data.get('æˆåˆ†è¡¨', [])
            if not ingredients:
                logger.info("æ²’æœ‰æˆåˆ†è¡¨è³‡æ–™ï¼Œè·³éæ›¿æ›")
                return
            
            logger.info(f"é–‹å§‹æ›¿æ›æˆåˆ†è¡¨ï¼Œå…± {len(ingredients)} å€‹æˆåˆ†")
            
            # æª¢æŸ¥æ‰€æœ‰è¡¨æ ¼
            for table_idx, table in enumerate(doc.tables):
                if self._is_ingredients_table(table):
                    logger.info(f"æ›¿æ›è¡¨æ ¼ {table_idx} çš„æˆåˆ†è¡¨")
                    self._replace_ingredients_table(table, ingredients)
            
            # ä¿å­˜ä¿®æ”¹å¾Œçš„æ–‡æª”
            doc.save(str(doc_path))
            logger.info("æˆåˆ†è¡¨æ›¿æ›å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ›¿æ›æˆåˆ†è¡¨å¤±æ•—: {e}")
            # ä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½ï¼Œåªè¨˜éŒ„éŒ¯èª¤
    
    def _highlight_inserted_data(self, output_path: Path, data: Dict[str, Any]) -> None:
        """ç‚ºæ’å…¥çš„è³‡æ–™æ·»åŠ æ·ºè—åº•è‰²æ¨™è¨˜"""
        try:
            from docx import Document
            from docx.shared import RGBColor
            from docx.oxml.shared import qn
            
            doc = Document(str(output_path))
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦æ¨™è¨˜çš„è³‡æ–™å€¼
            data_values = set()
            
            def collect_values(obj: Any, prefix: str = ""):
                """éæ­¸æ”¶é›†æ‰€æœ‰è³‡æ–™å€¼"""
                if isinstance(obj, dict):
                    for k, v in obj.items():
                        collect_values(v, f"{prefix}.{k}" if prefix else k)
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        if isinstance(item, dict):
                            collect_values(item, f"{prefix}[{i}]")
                        else:
                            value = str(item).strip() if item is not None else ""
                            if value and len(value) > 2:  # åªæ”¶é›†é•·åº¦å¤§æ–¼2çš„å€¼
                                data_values.add(value)
                else:
                    value = str(obj).strip() if obj is not None else ""
                    if value and len(value) > 2:  # åªæ”¶é›†é•·åº¦å¤§æ–¼2çš„å€¼
                        data_values.add(value)
            
            collect_values(data)
            
            # ç‰¹åˆ¥è™•ç†æˆåˆ†è¡¨è³‡æ–™
            ingredients_data = data.get('æˆåˆ†è¡¨', [])
            if isinstance(ingredients_data, list):
                for ingredient in ingredients_data:
                    if isinstance(ingredient, dict):
                        for field in ['INCIåç¨±', 'CASè™Ÿç¢¼', 'å«é‡', 'åŠŸèƒ½']:
                            value = str(ingredient.get(field, '')).strip()
                            if value and len(value) > 1:
                                data_values.add(value)
            
            # æ·ºè—è‰²èƒŒæ™¯
            light_blue = RGBColor(173, 216, 230)  # æ·ºè—è‰²
            
            # è™•ç†æ®µè½ä¸­çš„è³‡æ–™
            for paragraph in doc.paragraphs:
                for run in paragraph.runs:
                    run_text = run.text.strip()
                    if run_text and any(value in run_text for value in data_values):
                        # è¨­ç½®æ·ºè—è‰²èƒŒæ™¯
                        run.font.highlight_color = None  # æ¸…é™¤ç¾æœ‰é«˜äº®
                        # ä½¿ç”¨shadingä»£æ›¿highlightï¼ˆæ›´æ˜é¡¯ï¼‰
                        try:
                            from docx.oxml import OxmlElement
                            shading = OxmlElement('w:shd')
                            shading.set(qn('w:val'), 'clear')
                            shading.set(qn('w:color'), 'auto')
                            shading.set(qn('w:fill'), 'B4D4E6')
                            run._element.get_or_add_rPr().append(shading)
                        except Exception as e:
                            logger.warning(f"æ·»åŠ èƒŒæ™¯æ¨™è¨˜å¤±æ•—: {e}")
            
            # è™•ç†è¡¨æ ¼ä¸­çš„è³‡æ–™
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for paragraph in cell.paragraphs:
                            for run in paragraph.runs:
                                run_text = run.text.strip()
                                if run_text and any(value in run_text for value in data_values):
                                    # è¨­ç½®æ·ºè—è‰²èƒŒæ™¯
                                    try:
                                        from docx.oxml import OxmlElement
                                        shading = OxmlElement('w:shd')
                                        shading.set(qn('w:val'), 'clear')
                                        shading.set(qn('w:color'), 'auto')
                                        shading.set(qn('w:fill'), 'B4D4E6')
                                        run._element.get_or_add_rPr().append(shading)
                                    except Exception as e:
                                        logger.warning(f"æ·»åŠ èƒŒæ™¯æ¨™è¨˜å¤±æ•—: {e}")
            
            # ä¿å­˜ä¿®æ”¹å¾Œçš„æ–‡æª”
            doc.save(str(output_path))
            logger.info(f"å·²ç‚ºæ’å…¥çš„è³‡æ–™æ·»åŠ æ·ºè—åº•è‰²æ¨™è¨˜ï¼Œå…±æ¨™è¨˜ {len(data_values)} å€‹è³‡æ–™å€¼")
            
        except Exception as e:
            logger.warning(f"æ·»åŠ æ·ºè—åº•è‰²æ¨™è¨˜å¤±æ•—: {e}")
            # ä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½ï¼Œåªè¨˜éŒ„è­¦å‘Š
    
    def _transform_to_pdf(self, data: Dict[str, Any], 
                         template_path: Path, output_path: Path, allow_fallback: bool = False) -> bool:
        """è½‰æ›ç‚ºPDFæ–‡æª”"""
        try:
            # å…ˆè½‰æ›ç‚ºWordï¼Œå†è½‰ç‚ºPDF
            temp_docx = output_path.with_suffix('.docx')
            
            if self._transform_to_docx(data, template_path, temp_docx, allow_fallback):
                # è½‰æ›ç‚ºPDF
                return self._docx_to_pdf(temp_docx, output_path)
            else:
                return False
                
        except Exception as e:
            logger.error(f"PDFè½‰æ›å¤±æ•—: {e}")
            # ç›´æ¥æ‹‹å‡ºç•°å¸¸ï¼Œä¸ä½¿ç”¨å›é€€æ©Ÿåˆ¶
            raise Exception(f"PDFè½‰æ›å¤±æ•—: {e}")
    
    def _docx_to_pdf(self, docx_path: Path, pdf_path: Path) -> bool:
        """å°‡Wordæ–‡æª”è½‰æ›ç‚ºPDF"""
        try:
            # å˜—è©¦ä½¿ç”¨docx2pdf
            try:
                from docx2pdf import convert
                convert(str(docx_path), str(pdf_path))
                return True
            except ImportError:
                logger.warning("docx2pdfæœªå®‰è£ï¼Œå˜—è©¦å…¶ä»–æ–¹æ³•")
            
            # å˜—è©¦ä½¿ç”¨LibreOffice
            try:
                import subprocess
                result = subprocess.run([
                    'libreoffice', '--headless', '--convert-to', 'pdf',
                    '--outdir', str(pdf_path.parent),
                    str(docx_path)
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    return True
                else:
                    logger.error(f"LibreOfficeè½‰æ›å¤±æ•—: {result.stderr}")
                    return False
                    
            except FileNotFoundError:
                logger.error("LibreOfficeæœªå®‰è£")
                return False
                
        except Exception as e:
            logger.error(f"PDFè½‰æ›å¤±æ•—: {e}")
            # ç›´æ¥æ‹‹å‡ºç•°å¸¸ï¼Œä¸ä½¿ç”¨å›é€€æ©Ÿåˆ¶
            raise Exception(f"PDFè½‰æ›å¤±æ•—: {e}")
    
    def _transform_to_json(self, data: Dict[str, Any], output_path: Path) -> bool:
        """è½‰æ›ç‚ºJSONæª”æ¡ˆ"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"JSONæª”æ¡ˆå·²ç”Ÿæˆ: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"JSONè½‰æ›å¤±æ•—: {e}")
            # ç›´æ¥æ‹‹å‡ºç•°å¸¸ï¼Œä¸ä½¿ç”¨å›é€€æ©Ÿåˆ¶
            raise Exception(f"JSONè½‰æ›å¤±æ•—: {e}")
    
    def get_available_templates(self) -> List[Dict[str, str]]:
        """ç²å–å¯ç”¨çš„æ¨¡æ¿åˆ—è¡¨"""
        templates = []
        
        if self.template_dir.exists():
            for template_file in self.template_dir.iterdir():
                if template_file.is_file() and template_file.suffix.lower() in [".docx", ".doc", ".pdf"]:
                    templates.append({
                        "name": template_file.stem,
                        "filename": template_file.name,
                        "path": str(template_file),
                        "type": template_file.suffix.lower().lstrip(".")
                    })
        
        return templates
    
    def create_template(self, template_name: str, 
                       structure: Dict[str, Any]) -> bool:
        """
        å‰µå»ºæ–°æ¨¡æ¿
        
        Args:
            template_name: æ¨¡æ¿åç¨±
            structure: æ–‡æª”çµæ§‹å®šç¾©
            
        Returns:
            å‰µå»ºæ˜¯å¦æˆåŠŸ
        """
        try:
            # é€™è£¡å¯ä»¥å¯¦ç¾æ¨¡æ¿å‰µå»ºé‚è¼¯
            # æš«æ™‚è¿”å›False
            logger.info(f"æ¨¡æ¿å‰µå»ºåŠŸèƒ½å¾…å¯¦ç¾: {template_name}")
            return False
            
        except Exception as e:
            logger.error(f"æ¨¡æ¿å‰µå»ºå¤±æ•—: {e}")
            return False


